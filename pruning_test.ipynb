{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genericpath import isfile\n",
    "import json\n",
    "import os\n",
    "if __name__ == '__main__':\n",
    "    #os.sys.path.append('./pytorch_geometric/torch_geometric')\n",
    "    os.sys.path.append('./src')\n",
    "from src.model.model import MMGNet\n",
    "from src.model.SGFN_MMG.baseline_sgfn import SGFN\n",
    "from src.model.SGFN_MMG.baseline_sgpn import SGPN\n",
    "from src.utils.config import Config\n",
    "from utils import util\n",
    "import torch\n",
    "import argparse\n",
    "import torch.nn.utils.prune as prune\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['config/ckp/Mmgnet/origin_t3/rel_encoder_3d_best.pth', 'config/ckp/Mmgnet/origin_t3/rel_predictor_3d_best.pth', 'config/ckp/Mmgnet/origin_t3/rel_encoder_2d_best.pth', 'config/ckp/Mmgnet/origin_t3/rel_predictor_2d_best.pth', 'config/ckp/Mmgnet/origin_t3/clip_model_best.pth', 'config/ckp/Mmgnet/origin_t3/triplet_projector_2d_best.pth', 'config/ckp/Mmgnet/origin_t3/mlp_3d_best.pth', 'config/ckp/Mmgnet/origin_t3/mmg_best.pth', 'config/ckp/Mmgnet/origin_t3/optimizer_best.pth', 'config/ckp/Mmgnet/origin_t3/clip_adapter_best.pth', 'config/ckp/Mmgnet/origin_t3/config_best.pth', 'config/ckp/Mmgnet/origin_t3/lr_scheduler_best.pth', 'config/ckp/Mmgnet/origin_t3/obj_predictor_2d_best.pth', 'config/ckp/Mmgnet/origin_t3/obj_predictor_3d_best.pth', 'config/ckp/Mmgnet/origin_t3/obj_encoder_best.pth', 'config/ckp/Mmgnet/origin_t3/triplet_projector_3d_best.pth']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# 디렉토리 경로 설정\n",
    "directory = 'config/ckp/Mmgnet/origin_t3/'\n",
    "\n",
    "# _best.pth 파일들의 목록을 가져오기\n",
    "best_files = glob.glob(os.path.join(directory, '*_pre.pth'))\n",
    "print(best_files)\n",
    "# 파일 이름 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed: config/ckp/Mmgnet/origin_t3/rel_encoder_3d_best.pth -> config/ckp/Mmgnet/origin_t3/rel_encoder_3d_pre.pth\n",
      "Renamed: config/ckp/Mmgnet/origin_t3/rel_predictor_3d_best.pth -> config/ckp/Mmgnet/origin_t3/rel_predictor_3d_pre.pth\n",
      "Renamed: config/ckp/Mmgnet/origin_t3/rel_encoder_2d_best.pth -> config/ckp/Mmgnet/origin_t3/rel_encoder_2d_pre.pth\n",
      "Renamed: config/ckp/Mmgnet/origin_t3/rel_predictor_2d_best.pth -> config/ckp/Mmgnet/origin_t3/rel_predictor_2d_pre.pth\n",
      "Renamed: config/ckp/Mmgnet/origin_t3/clip_model_best.pth -> config/ckp/Mmgnet/origin_t3/clip_model_pre.pth\n",
      "Renamed: config/ckp/Mmgnet/origin_t3/triplet_projector_2d_best.pth -> config/ckp/Mmgnet/origin_t3/triplet_projector_2d_pre.pth\n",
      "Renamed: config/ckp/Mmgnet/origin_t3/mlp_3d_best.pth -> config/ckp/Mmgnet/origin_t3/mlp_3d_pre.pth\n",
      "Renamed: config/ckp/Mmgnet/origin_t3/mmg_best.pth -> config/ckp/Mmgnet/origin_t3/mmg_pre.pth\n",
      "Renamed: config/ckp/Mmgnet/origin_t3/optimizer_best.pth -> config/ckp/Mmgnet/origin_t3/optimizer_pre.pth\n",
      "Renamed: config/ckp/Mmgnet/origin_t3/clip_adapter_best.pth -> config/ckp/Mmgnet/origin_t3/clip_adapter_pre.pth\n",
      "Renamed: config/ckp/Mmgnet/origin_t3/config_best.pth -> config/ckp/Mmgnet/origin_t3/config_pre.pth\n",
      "Renamed: config/ckp/Mmgnet/origin_t3/lr_scheduler_best.pth -> config/ckp/Mmgnet/origin_t3/lr_scheduler_pre.pth\n",
      "Renamed: config/ckp/Mmgnet/origin_t3/obj_predictor_2d_best.pth -> config/ckp/Mmgnet/origin_t3/obj_predictor_2d_pre.pth\n",
      "Renamed: config/ckp/Mmgnet/origin_t3/obj_predictor_3d_best.pth -> config/ckp/Mmgnet/origin_t3/obj_predictor_3d_pre.pth\n",
      "Renamed: config/ckp/Mmgnet/origin_t3/obj_encoder_best.pth -> config/ckp/Mmgnet/origin_t3/obj_encoder_pre.pth\n",
      "Renamed: config/ckp/Mmgnet/origin_t3/triplet_projector_3d_best.pth -> config/ckp/Mmgnet/origin_t3/triplet_projector_3d_pre.pth\n"
     ]
    }
   ],
   "source": [
    "for file_path in best_files:\n",
    "    # 새 파일 이름 생성\n",
    "    new_file_path = file_path.replace('_pre.pth', '_best.pth')\n",
    "    # 파일 이름 변경\n",
    "    os.rename(file_path, new_file_path)\n",
    "    print(f'Renamed: {file_path} -> {new_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config():\n",
    "    # load config file\n",
    "    config = Config(\"./config/mmgnet.json\")\n",
    "    #print(config)\n",
    "    config.MODE = 'train'\n",
    "    config.exp = 'test'\n",
    "    config.NAME = 'mmg'\n",
    "    \n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name : mmg\n",
      "=== 160 classes ===\n",
      "| 0             armchair:0.006|| 1             backpack:0.019|\n",
      "| 2                  bag:0.005|| 3                 ball:0.143|\n",
      "| 4                  bar:0.071|| 5                basin:0.286|\n",
      "| 6               basket:0.009|| 7         bath cabinet:0.016|\n",
      "| 8              bathtub:0.036|| 9                  bed:0.009|\n",
      "|10        bedside table:0.061||11                bench:0.011|\n",
      "|12                bidet:0.200||13                  bin:0.037|\n",
      "|14              blanket:0.007||15               blinds:0.014|\n",
      "|16                board:0.087||17                 book:0.050|\n",
      "|18                books:0.080||19            bookshelf:0.065|\n",
      "|20               bottle:0.041||21                  box:0.001|\n",
      "|22                bread:0.286||23               bucket:0.015|\n",
      "|24              cabinet:0.004||25               carpet:0.061|\n",
      "|26              ceiling:0.002||27                chair:0.001|\n",
      "|28             cleanser:0.500||29                clock:0.059|\n",
      "|30               closet:0.083||31              clothes:0.006|\n",
      "|32        clothes dryer:0.030||33              clutter:0.016|\n",
      "|34       coffee machine:0.080||35         coffee table:0.015|\n",
      "|36              commode:0.008||37        computer desk:0.250|\n",
      "|38                couch:0.025||39          couch table:0.040|\n",
      "|40              counter:0.021||41                  cup:0.286|\n",
      "|42             cupboard:0.038||43              curtain:0.003|\n",
      "|44              cushion:0.011||45        cutting board:0.080|\n",
      "|46           decoration:0.022||47                 desk:0.008|\n",
      "|48         dining chair:0.038||49         dining table:0.050|\n",
      "|50                 door:0.003||51            doorframe:0.006|\n",
      "|52               drawer:0.059||53                 drum:0.667|\n",
      "|54       drying machine:0.154||55        extractor fan:0.250|\n",
      "|56            fireplace:0.105||57                floor:0.001|\n",
      "|58               flower:0.057||59              flowers:0.077|\n",
      "|60               folder:0.200||61                 food:0.182|\n",
      "|62            footstool:0.400||63                frame:0.026|\n",
      "|64          fruit plate:1.000||65              garbage:0.054|\n",
      "|66          garbage bin:0.087||67                grass:0.500|\n",
      "|68           hand dryer:0.133||69               heater:0.007|\n",
      "|70                 item:0.003||71               jacket:1.000|\n",
      "|72                  jar:0.125||73               kettle:0.047|\n",
      "|74    kitchen appliance:0.024||75      kitchen cabinet:0.006|\n",
      "|76      kitchen counter:0.016||77         kitchen hood:0.222|\n",
      "|78               ladder:0.111||79                 lamp:0.003|\n",
      "|80               laptop:0.036||81       laundry basket:0.059|\n",
      "|82                light:0.006||83              machine:0.250|\n",
      "|84        magazine rack:0.667||85                 menu:1.000|\n",
      "|86            microwave:0.030||87               mirror:0.018|\n",
      "|88              monitor:0.009||89              napkins:0.143|\n",
      "|90           nightstand:0.013||91               object:0.004|\n",
      "|92              objects:0.105||93            organizer:0.056|\n",
      "|94              ottoman:0.048||95                 oven:0.028|\n",
      "|96                 pack:0.059||97                  pan:0.167|\n",
      "|98          paper towel:0.091||99               papers:0.286|\n",
      "|100                   pc:0.022||101              picture:0.005|\n",
      "|102        pile of books:0.154||103       pile of papers:0.400|\n",
      "|104               pillow:0.001||105                 pipe:0.047|\n",
      "|106                plant:0.003||107                plate:0.041|\n",
      "|108               player:0.250||109                  pot:0.054|\n",
      "|110              printer:0.047||111                 rack:0.020|\n",
      "|112             radiator:0.014||113          recycle bin:0.111|\n",
      "|114         refrigerator:0.027||115        rocking chair:0.667|\n",
      "|116                scale:0.087||117               screen:0.667|\n",
      "|118                shelf:0.002||119                 shoe:0.400|\n",
      "|120            shoe rack:0.400||121                shoes:0.024|\n",
      "|122             showcase:0.034||123               shower:0.043|\n",
      "|124       shower curtain:0.044||125         shower floor:0.200|\n",
      "|126          shower wall:0.077||127           side table:0.033|\n",
      "|128                 sink:0.006||129            soap dish:0.500|\n",
      "|130               socket:0.286||131                 sofa:0.010|\n",
      "|132           sofa chair:0.083||133                stair:0.143|\n",
      "|134                stand:0.017||135                stool:0.007|\n",
      "|136                stove:0.024||137       stuffed animal:0.069|\n",
      "|138             suitcase:0.036||139                table:0.003|\n",
      "|140           table lamp:0.077||141            telephone:0.042|\n",
      "|142              toaster:0.250||143               toilet:0.016|\n",
      "|144         toilet brush:0.074||145         toilet paper:0.043|\n",
      "|146 toilet paper dispenser:0.250||147                towel:0.007|\n",
      "|148            trash can:0.007||149             trashcan:0.333|\n",
      "|150                 tube:0.095||151                   tv:0.012|\n",
      "|152             tv stand:0.026||153                 vase:0.035|\n",
      "|154                 wall:0.000||155             wardrobe:0.009|\n",
      "|156      washing machine:0.027||157       washing powder:0.250|\n",
      "|158               window:0.003||159           windowsill:0.009|\n",
      "\n",
      "=== 26 relationships ===\n",
      "| 0         supported by 0.001|| 1                 left 0.000|\n",
      "| 2                right 0.000|| 3                front 0.000|\n",
      "| 4               behind 0.000|| 5             close by 0.000|\n",
      "| 6               inside 1.000|| 7          bigger than 0.001|\n",
      "| 8         smaller than 0.001|| 9          higher than 0.001|\n",
      "|10           lower than 0.001||11     same symmetry as 0.004|\n",
      "|12              same as 0.000||13          attached to 0.000|\n",
      "|14          standing on 0.000||15             lying on 0.000|\n",
      "|16           hanging on 0.001||17         connected to 0.005|\n",
      "|18      leaning against 0.005||19              part of 0.015|\n",
      "|20         belonging to 0.006||21             build in 0.004|\n",
      "|22          standing in 0.004||23                cover 0.022|\n",
      "|24             lying in 0.010||25           hanging in 0.100|\n",
      "\n",
      "num of data: 3845\n",
      "=== 160 classes ===\n",
      "| 0             armchair:0.045|| 1             backpack:0.400|\n",
      "| 2                  bag:0.056|| 3                 ball:0.400|\n",
      "| 4                  bar:0.500|| 5                basin:0.500|\n",
      "| 6               basket:0.182|| 7         bath cabinet:0.080|\n",
      "| 8              bathtub:0.400|| 9                  bed:0.286|\n",
      "|10        bedside table:0.400||11                bench:0.105|\n",
      "|12                bidet:0.667||13                  bin:0.667|\n",
      "|14              blanket:0.044||15               blinds:0.400|\n",
      "|16                board:0.333||17                 book:0.182|\n",
      "|18                books:0.333||19            bookshelf:0.250|\n",
      "|20               bottle:0.500||21                  box:0.019|\n",
      "|22                bread:1.000||23               bucket:0.250|\n",
      "|24              cabinet:0.016||25               carpet:0.250|\n",
      "|26              ceiling:0.012||27                chair:0.010|\n",
      "|28             cleanser:0.400||29                clock:0.095|\n",
      "|30               closet:0.667||31              clothes:0.095|\n",
      "|32        clothes dryer:0.667||33              clutter:0.061|\n",
      "|34       coffee machine:0.500||35         coffee table:0.069|\n",
      "|36              commode:0.062||37        computer desk:0.333|\n",
      "|38                couch:0.053||39          couch table:0.118|\n",
      "|40              counter:0.143||41                  cup:1.000|\n",
      "|42             cupboard:0.200||43              curtain:0.017|\n",
      "|44              cushion:0.033||45        cutting board:0.250|\n",
      "|46           decoration:0.056||47                 desk:0.100|\n",
      "|48         dining chair:0.182||49         dining table:0.286|\n",
      "|50                 door:0.018||51            doorframe:0.035|\n",
      "|52               drawer:0.333||53                 drum:0.333|\n",
      "|54       drying machine:0.200||55        extractor fan:0.500|\n",
      "|56            fireplace:0.154||57                floor:0.004|\n",
      "|58               flower:0.250||59              flowers:0.200|\n",
      "|60               folder:0.250||61                 food:0.333|\n",
      "|62            footstool:0.667||63                frame:0.118|\n",
      "|64          fruit plate:0.500||65              garbage:0.400|\n",
      "|66          garbage bin:0.286||67                grass:0.667|\n",
      "|68           hand dryer:0.286||69               heater:0.051|\n",
      "|70                 item:0.025||71               jacket:0.667|\n",
      "|72                  jar:0.250||73               kettle:0.250|\n",
      "|74    kitchen appliance:0.167||75      kitchen cabinet:0.036|\n",
      "|76      kitchen counter:0.105||77         kitchen hood:0.286|\n",
      "|78               ladder:0.667||79                 lamp:0.019|\n",
      "|80               laptop:0.500||81       laundry basket:0.182|\n",
      "|82                light:0.062||83              machine:0.500|\n",
      "|84        magazine rack:0.667||85                 menu:0.154|\n",
      "|86            microwave:0.182||87               mirror:0.222|\n",
      "|88              monitor:0.118||89              napkins:1.000|\n",
      "|90           nightstand:1.000||91               object:0.027|\n",
      "|92              objects:1.000||93            organizer:0.500|\n",
      "|94              ottoman:0.065||95                 oven:0.118|\n",
      "|96                 pack:0.133||97                  pan:0.667|\n",
      "|98          paper towel:0.500||99               papers:1.000|\n",
      "|100                   pc:0.500||101              picture:0.024|\n",
      "|102        pile of books:0.222||103       pile of papers:0.400|\n",
      "|104               pillow:0.010||105                 pipe:0.400|\n",
      "|106                plant:0.013||107                plate:0.182|\n",
      "|108               player:0.500||109                  pot:0.250|\n",
      "|110              printer:0.143||111                 rack:0.167|\n",
      "|112             radiator:0.100||113          recycle bin:1.000|\n",
      "|114         refrigerator:0.286||115        rocking chair:0.667|\n",
      "|116                scale:0.667||117               screen:0.333|\n",
      "|118                shelf:0.014||119                 shoe:0.400|\n",
      "|120            shoe rack:0.500||121                shoes:0.333|\n",
      "|122             showcase:0.167||123               shower:0.500|\n",
      "|124       shower curtain:0.250||125         shower floor:0.667|\n",
      "|126          shower wall:0.087||127           side table:0.083|\n",
      "|128                 sink:0.033||129            soap dish:0.667|\n",
      "|130               socket:1.000||131                 sofa:0.054|\n",
      "|132           sofa chair:0.400||133                stair:0.500|\n",
      "|134                stand:0.143||135                stool:0.087|\n",
      "|136                stove:0.111||137       stuffed animal:1.000|\n",
      "|138             suitcase:0.286||139                table:0.023|\n",
      "|140           table lamp:0.250||141            telephone:0.333|\n",
      "|142              toaster:0.400||143               toilet:0.071|\n",
      "|144         toilet brush:0.200||145         toilet paper:0.167|\n",
      "|146 toilet paper dispenser:0.182||147                towel:0.071|\n",
      "|148            trash can:0.059||149             trashcan:0.500|\n",
      "|150                 tube:0.500||151                   tv:0.051|\n",
      "|152             tv stand:0.062||153                 vase:0.053|\n",
      "|154                 wall:0.003||155             wardrobe:0.143|\n",
      "|156      washing machine:0.133||157       washing powder:1.000|\n",
      "|158               window:0.023||159           windowsill:0.118|\n",
      "\n",
      "=== 26 relationships ===\n",
      "| 0         supported by 0.004|| 1                 left 0.001|\n",
      "| 2                right 0.001|| 3                front 0.001|\n",
      "| 4               behind 0.001|| 5             close by 0.001|\n",
      "| 6               inside 1.000|| 7          bigger than 0.012|\n",
      "| 8         smaller than 0.012|| 9          higher than 0.005|\n",
      "|10           lower than 0.005||11     same symmetry as 0.020|\n",
      "|12              same as 0.005||13          attached to 0.001|\n",
      "|14          standing on 0.001||15             lying on 0.004|\n",
      "|16           hanging on 0.006||17         connected to 0.029|\n",
      "|18      leaning against 0.050||19              part of 0.143|\n",
      "|20         belonging to 0.031||21             build in 0.029|\n",
      "|22          standing in 0.038||23                cover 0.053|\n",
      "|24             lying in 0.027||25           hanging in 0.500|\n",
      "\n",
      "num of data: 548\n",
      "self.model_name:  mmg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.model.model.MMGNet at 0x7f42433e5fd0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = load_config()\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"0\"\n",
    "util.set_random_seed(config.SEED)\n",
    "\n",
    "# if config.VERBOSE:\n",
    "#     print(config)\n",
    "\n",
    "model = MMGNet(config)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv1d(96, 32, kernel_size=(1,), stride=(1,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.gcn.gconvs[0].edgeatten.nn[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mmgnet_teacher(\n",
       "  (obj_encoder): PointNetfeat(\n",
       "    (relu): ReLU()\n",
       "    (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "    (conv3): Conv1d(128, 768, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (rel_encoder_2d): PointNetfeat(\n",
       "    (relu): ReLU()\n",
       "    (conv1): Conv1d(11, 64, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "    (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (rel_encoder_3d): PointNetfeat(\n",
       "    (relu): ReLU()\n",
       "    (conv1): Conv1d(11, 64, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "    (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (mmg): MMG(\n",
       "    (self_attn): ModuleList(\n",
       "      (0): MultiHeadAttention(\n",
       "        (attention): ScaledDotProductAttention(\n",
       "          (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): MultiHeadAttention(\n",
       "        (attention): ScaledDotProductAttention(\n",
       "          (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (cross_attn): ModuleList(\n",
       "      (0): MultiHeadAttention(\n",
       "        (attention): ScaledDotProductAttention(\n",
       "          (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): MultiHeadAttention(\n",
       "        (attention): ScaledDotProductAttention(\n",
       "          (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (cross_attn_rel): ModuleList(\n",
       "      (0): MultiHeadAttention(\n",
       "        (attention): ScaledDotProductAttention(\n",
       "          (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): MultiHeadAttention(\n",
       "        (attention): ScaledDotProductAttention(\n",
       "          (fc_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (gcn_2ds): ModuleList(\n",
       "      (0): GraphEdgeAttenNetwork(\n",
       "        (index_get): Gen_Index()\n",
       "        (index_aggr): Aggre_Index()\n",
       "        (edgeatten): MultiHeadedEdgeAttention(\n",
       "          (nn_edge): Sequential(\n",
       "            (0): Linear(in_features=1536, out_features=1024, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          )\n",
       "          (nn): mySequential(\n",
       "            (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "            (1): ReLU()\n",
       "            (2): Dropout(p=0.5, inplace=False)\n",
       "            (3): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (proj_edge): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (proj_query): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (proj_value): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (prop): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=768, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): GraphEdgeAttenNetwork(\n",
       "        (index_get): Gen_Index()\n",
       "        (index_aggr): Aggre_Index()\n",
       "        (edgeatten): MultiHeadedEdgeAttention(\n",
       "          (nn_edge): Sequential(\n",
       "            (0): Linear(in_features=1536, out_features=1024, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          )\n",
       "          (nn): mySequential(\n",
       "            (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "            (1): ReLU()\n",
       "            (2): Dropout(p=0.5, inplace=False)\n",
       "            (3): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (proj_edge): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (proj_query): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (proj_value): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (prop): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=768, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (gcn_3ds): ModuleList(\n",
       "      (0): GraphEdgeAttenNetwork(\n",
       "        (index_get): Gen_Index()\n",
       "        (index_aggr): Aggre_Index()\n",
       "        (edgeatten): MultiHeadedEdgeAttention(\n",
       "          (nn_edge): Sequential(\n",
       "            (0): Linear(in_features=1536, out_features=1024, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          )\n",
       "          (nn): mySequential(\n",
       "            (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "            (1): ReLU()\n",
       "            (2): Dropout(p=0.5, inplace=False)\n",
       "            (3): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (proj_edge): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (proj_query): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (proj_value): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (prop): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=768, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): GraphEdgeAttenNetwork(\n",
       "        (index_get): Gen_Index()\n",
       "        (index_aggr): Aggre_Index()\n",
       "        (edgeatten): MultiHeadedEdgeAttention(\n",
       "          (nn_edge): Sequential(\n",
       "            (0): Linear(in_features=1536, out_features=1024, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          )\n",
       "          (nn): mySequential(\n",
       "            (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "            (1): ReLU()\n",
       "            (2): Dropout(p=0.5, inplace=False)\n",
       "            (3): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (proj_edge): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (proj_query): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (proj_value): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (prop): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=768, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (self_attn_fc): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=32, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (6): Linear(in_features=32, out_features=8, bias=True)\n",
       "    )\n",
       "    (drop_out): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (triplet_projector_3d): Sequential(\n",
       "    (0): Linear(in_features=1536, out_features=1024, bias=True)\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (triplet_projector_2d): Sequential(\n",
       "    (0): Linear(in_features=1536, out_features=1024, bias=True)\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (clip_adapter): AdapterModel(\n",
       "    (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
       "  )\n",
       "  (mlp_3d): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=504, bias=True)\n",
       "    (1): BatchNorm1d(504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (rel_predictor_3d): PointNetRelClsMulti(\n",
       "    (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (fc3): Linear(in_features=256, out_features=26, bias=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (rel_predictor_2d): PointNetRelClsMulti(\n",
       "    (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (fc3): Linear(in_features=256, out_features=26, bias=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (clip_model): CLIP(\n",
       "    (visual): VisionTransformer(\n",
       "      (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): Sequential(\n",
       "          (0): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): Sequential(\n",
       "        (0): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (token_embedding): Embedding(49408, 512)\n",
       "    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (obj_predictor_2d): Linear(in_features=512, out_features=160, bias=True)\n",
       "  (obj_predictor_3d): Linear(in_features=512, out_features=160, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnn pruning start\n",
      "gnn: mmg pruning:0.5 start!\n",
      "gnn pruning success!\n"
     ]
    }
   ],
   "source": [
    "model.apply_pruning(\"gnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: obj_logit_scale, num_params: 1, non_zero_params: 1\n",
      "name: obj_encoder.conv1.weight, num_params: 192, non_zero_params: 192\n",
      "name: obj_encoder.conv1.bias, num_params: 64, non_zero_params: 64\n",
      "name: obj_encoder.conv2.weight, num_params: 8192, non_zero_params: 8192\n",
      "name: obj_encoder.conv2.bias, num_params: 128, non_zero_params: 128\n",
      "name: obj_encoder.conv3.weight, num_params: 98304, non_zero_params: 98304\n",
      "name: obj_encoder.conv3.bias, num_params: 768, non_zero_params: 768\n",
      "name: rel_encoder_2d.conv1.weight, num_params: 704, non_zero_params: 704\n",
      "name: rel_encoder_2d.conv1.bias, num_params: 64, non_zero_params: 64\n",
      "name: rel_encoder_2d.conv2.weight, num_params: 8192, non_zero_params: 8192\n",
      "name: rel_encoder_2d.conv2.bias, num_params: 128, non_zero_params: 128\n",
      "name: rel_encoder_2d.conv3.weight, num_params: 65536, non_zero_params: 65536\n",
      "name: rel_encoder_2d.conv3.bias, num_params: 512, non_zero_params: 512\n",
      "name: rel_encoder_3d.conv1.weight, num_params: 704, non_zero_params: 704\n",
      "name: rel_encoder_3d.conv1.bias, num_params: 64, non_zero_params: 64\n",
      "name: rel_encoder_3d.conv2.weight, num_params: 8192, non_zero_params: 8192\n",
      "name: rel_encoder_3d.conv2.bias, num_params: 128, non_zero_params: 128\n",
      "name: rel_encoder_3d.conv3.weight, num_params: 65536, non_zero_params: 65536\n",
      "name: rel_encoder_3d.conv3.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.self_attn.0.attention.fc_q.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.self_attn.0.attention.fc_q.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.self_attn.0.attention.fc_k.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.self_attn.0.attention.fc_k.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.self_attn.0.attention.fc_v.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.self_attn.0.attention.fc_v.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.self_attn.0.attention.fc_o.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.self_attn.0.attention.fc_o.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.self_attn.0.layer_norm.weight, num_params: 512, non_zero_params: 512\n",
      "name: mmg.self_attn.0.layer_norm.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.self_attn.1.attention.fc_q.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.self_attn.1.attention.fc_q.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.self_attn.1.attention.fc_k.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.self_attn.1.attention.fc_k.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.self_attn.1.attention.fc_v.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.self_attn.1.attention.fc_v.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.self_attn.1.attention.fc_o.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.self_attn.1.attention.fc_o.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.self_attn.1.layer_norm.weight, num_params: 512, non_zero_params: 512\n",
      "name: mmg.self_attn.1.layer_norm.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.cross_attn.0.attention.fc_q.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.cross_attn.0.attention.fc_q.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.cross_attn.0.attention.fc_k.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.cross_attn.0.attention.fc_k.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.cross_attn.0.attention.fc_v.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.cross_attn.0.attention.fc_v.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.cross_attn.0.attention.fc_o.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.cross_attn.0.attention.fc_o.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.cross_attn.0.layer_norm.weight, num_params: 512, non_zero_params: 512\n",
      "name: mmg.cross_attn.0.layer_norm.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.cross_attn.1.attention.fc_q.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.cross_attn.1.attention.fc_q.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.cross_attn.1.attention.fc_k.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.cross_attn.1.attention.fc_k.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.cross_attn.1.attention.fc_v.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.cross_attn.1.attention.fc_v.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.cross_attn.1.attention.fc_o.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.cross_attn.1.attention.fc_o.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.cross_attn.1.layer_norm.weight, num_params: 512, non_zero_params: 512\n",
      "name: mmg.cross_attn.1.layer_norm.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.cross_attn_rel.0.attention.fc_q.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.cross_attn_rel.0.attention.fc_q.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.cross_attn_rel.0.attention.fc_k.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.cross_attn_rel.0.attention.fc_k.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.cross_attn_rel.0.attention.fc_v.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.cross_attn_rel.0.attention.fc_v.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.cross_attn_rel.0.attention.fc_o.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.cross_attn_rel.0.attention.fc_o.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.cross_attn_rel.0.layer_norm.weight, num_params: 512, non_zero_params: 512\n",
      "name: mmg.cross_attn_rel.0.layer_norm.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.cross_attn_rel.1.attention.fc_q.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.cross_attn_rel.1.attention.fc_q.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.cross_attn_rel.1.attention.fc_k.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.cross_attn_rel.1.attention.fc_k.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.cross_attn_rel.1.attention.fc_v.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.cross_attn_rel.1.attention.fc_v.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.cross_attn_rel.1.attention.fc_o.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.cross_attn_rel.1.attention.fc_o.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.cross_attn_rel.1.layer_norm.weight, num_params: 512, non_zero_params: 512\n",
      "name: mmg.cross_attn_rel.1.layer_norm.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.gcn_2ds.0.edgeatten.nn_edge.0.bias, num_params: 1024, non_zero_params: 1024\n",
      "name: mmg.gcn_2ds.0.edgeatten.nn_edge.0.weight, num_params: 1572864, non_zero_params: 786432\n",
      "name: mmg.gcn_2ds.0.edgeatten.nn_edge.2.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.gcn_2ds.0.edgeatten.nn_edge.2.weight, num_params: 524288, non_zero_params: 262144\n",
      "name: mmg.gcn_2ds.0.edgeatten.nn.0.weight, num_params: 16384, non_zero_params: 16384\n",
      "name: mmg.gcn_2ds.0.edgeatten.nn.0.bias, num_params: 128, non_zero_params: 128\n",
      "name: mmg.gcn_2ds.0.edgeatten.nn.3.weight, num_params: 4096, non_zero_params: 4096\n",
      "name: mmg.gcn_2ds.0.edgeatten.nn.3.bias, num_params: 32, non_zero_params: 32\n",
      "name: mmg.gcn_2ds.0.edgeatten.proj_edge.0.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.gcn_2ds.0.edgeatten.proj_edge.0.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.gcn_2ds.0.edgeatten.proj_query.0.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.gcn_2ds.0.edgeatten.proj_query.0.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.gcn_2ds.0.edgeatten.proj_value.0.bias, num_params: 256, non_zero_params: 256\n",
      "name: mmg.gcn_2ds.0.edgeatten.proj_value.0.weight, num_params: 131072, non_zero_params: 65536\n",
      "name: mmg.gcn_2ds.0.prop.0.bias, num_params: 768, non_zero_params: 768\n",
      "name: mmg.gcn_2ds.0.prop.0.weight, num_params: 589824, non_zero_params: 294912\n",
      "name: mmg.gcn_2ds.0.prop.2.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.gcn_2ds.0.prop.2.weight, num_params: 393216, non_zero_params: 196608\n",
      "name: mmg.gcn_2ds.1.edgeatten.nn_edge.0.bias, num_params: 1024, non_zero_params: 1024\n",
      "name: mmg.gcn_2ds.1.edgeatten.nn_edge.0.weight, num_params: 1572864, non_zero_params: 786432\n",
      "name: mmg.gcn_2ds.1.edgeatten.nn_edge.2.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.gcn_2ds.1.edgeatten.nn_edge.2.weight, num_params: 524288, non_zero_params: 262144\n",
      "name: mmg.gcn_2ds.1.edgeatten.nn.0.weight, num_params: 16384, non_zero_params: 16384\n",
      "name: mmg.gcn_2ds.1.edgeatten.nn.0.bias, num_params: 128, non_zero_params: 128\n",
      "name: mmg.gcn_2ds.1.edgeatten.nn.3.weight, num_params: 4096, non_zero_params: 4096\n",
      "name: mmg.gcn_2ds.1.edgeatten.nn.3.bias, num_params: 32, non_zero_params: 32\n",
      "name: mmg.gcn_2ds.1.edgeatten.proj_edge.0.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.gcn_2ds.1.edgeatten.proj_edge.0.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.gcn_2ds.1.edgeatten.proj_query.0.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.gcn_2ds.1.edgeatten.proj_query.0.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.gcn_2ds.1.edgeatten.proj_value.0.bias, num_params: 256, non_zero_params: 256\n",
      "name: mmg.gcn_2ds.1.edgeatten.proj_value.0.weight, num_params: 131072, non_zero_params: 65536\n",
      "name: mmg.gcn_2ds.1.prop.0.bias, num_params: 768, non_zero_params: 768\n",
      "name: mmg.gcn_2ds.1.prop.0.weight, num_params: 589824, non_zero_params: 294912\n",
      "name: mmg.gcn_2ds.1.prop.2.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.gcn_2ds.1.prop.2.weight, num_params: 393216, non_zero_params: 196608\n",
      "name: mmg.gcn_3ds.0.edgeatten.nn_edge.0.bias, num_params: 1024, non_zero_params: 1024\n",
      "name: mmg.gcn_3ds.0.edgeatten.nn_edge.0.weight, num_params: 1572864, non_zero_params: 786432\n",
      "name: mmg.gcn_3ds.0.edgeatten.nn_edge.2.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.gcn_3ds.0.edgeatten.nn_edge.2.weight, num_params: 524288, non_zero_params: 262144\n",
      "name: mmg.gcn_3ds.0.edgeatten.nn.0.weight, num_params: 16384, non_zero_params: 16384\n",
      "name: mmg.gcn_3ds.0.edgeatten.nn.0.bias, num_params: 128, non_zero_params: 128\n",
      "name: mmg.gcn_3ds.0.edgeatten.nn.3.weight, num_params: 4096, non_zero_params: 4096\n",
      "name: mmg.gcn_3ds.0.edgeatten.nn.3.bias, num_params: 32, non_zero_params: 32\n",
      "name: mmg.gcn_3ds.0.edgeatten.proj_edge.0.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.gcn_3ds.0.edgeatten.proj_edge.0.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.gcn_3ds.0.edgeatten.proj_query.0.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.gcn_3ds.0.edgeatten.proj_query.0.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.gcn_3ds.0.edgeatten.proj_value.0.bias, num_params: 256, non_zero_params: 256\n",
      "name: mmg.gcn_3ds.0.edgeatten.proj_value.0.weight, num_params: 131072, non_zero_params: 65536\n",
      "name: mmg.gcn_3ds.0.prop.0.bias, num_params: 768, non_zero_params: 768\n",
      "name: mmg.gcn_3ds.0.prop.0.weight, num_params: 589824, non_zero_params: 294912\n",
      "name: mmg.gcn_3ds.0.prop.2.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.gcn_3ds.0.prop.2.weight, num_params: 393216, non_zero_params: 196608\n",
      "name: mmg.gcn_3ds.1.edgeatten.nn_edge.0.bias, num_params: 1024, non_zero_params: 1024\n",
      "name: mmg.gcn_3ds.1.edgeatten.nn_edge.0.weight, num_params: 1572864, non_zero_params: 786432\n",
      "name: mmg.gcn_3ds.1.edgeatten.nn_edge.2.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.gcn_3ds.1.edgeatten.nn_edge.2.weight, num_params: 524288, non_zero_params: 262144\n",
      "name: mmg.gcn_3ds.1.edgeatten.nn.0.weight, num_params: 16384, non_zero_params: 16384\n",
      "name: mmg.gcn_3ds.1.edgeatten.nn.0.bias, num_params: 128, non_zero_params: 128\n",
      "name: mmg.gcn_3ds.1.edgeatten.nn.3.weight, num_params: 4096, non_zero_params: 4096\n",
      "name: mmg.gcn_3ds.1.edgeatten.nn.3.bias, num_params: 32, non_zero_params: 32\n",
      "name: mmg.gcn_3ds.1.edgeatten.proj_edge.0.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.gcn_3ds.1.edgeatten.proj_edge.0.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.gcn_3ds.1.edgeatten.proj_query.0.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.gcn_3ds.1.edgeatten.proj_query.0.weight, num_params: 262144, non_zero_params: 131072\n",
      "name: mmg.gcn_3ds.1.edgeatten.proj_value.0.bias, num_params: 256, non_zero_params: 256\n",
      "name: mmg.gcn_3ds.1.edgeatten.proj_value.0.weight, num_params: 131072, non_zero_params: 65536\n",
      "name: mmg.gcn_3ds.1.prop.0.bias, num_params: 768, non_zero_params: 768\n",
      "name: mmg.gcn_3ds.1.prop.0.weight, num_params: 589824, non_zero_params: 294912\n",
      "name: mmg.gcn_3ds.1.prop.2.bias, num_params: 512, non_zero_params: 512\n",
      "name: mmg.gcn_3ds.1.prop.2.weight, num_params: 393216, non_zero_params: 196608\n",
      "name: mmg.self_attn_fc.0.bias, num_params: 32, non_zero_params: 32\n",
      "name: mmg.self_attn_fc.0.weight, num_params: 128, non_zero_params: 64\n",
      "name: mmg.self_attn_fc.2.weight, num_params: 32, non_zero_params: 32\n",
      "name: mmg.self_attn_fc.2.bias, num_params: 32, non_zero_params: 32\n",
      "name: mmg.self_attn_fc.3.bias, num_params: 32, non_zero_params: 32\n",
      "name: mmg.self_attn_fc.3.weight, num_params: 1024, non_zero_params: 512\n",
      "name: mmg.self_attn_fc.5.weight, num_params: 32, non_zero_params: 32\n",
      "name: mmg.self_attn_fc.5.bias, num_params: 32, non_zero_params: 32\n",
      "name: mmg.self_attn_fc.6.bias, num_params: 8, non_zero_params: 8\n",
      "name: mmg.self_attn_fc.6.weight, num_params: 256, non_zero_params: 128\n",
      "name: triplet_projector_3d.0.weight, num_params: 1572864, non_zero_params: 1572864\n",
      "name: triplet_projector_3d.0.bias, num_params: 1024, non_zero_params: 1024\n",
      "name: triplet_projector_3d.3.weight, num_params: 524288, non_zero_params: 524288\n",
      "name: triplet_projector_3d.3.bias, num_params: 512, non_zero_params: 512\n",
      "name: triplet_projector_2d.0.weight, num_params: 1572864, non_zero_params: 1572864\n",
      "name: triplet_projector_2d.0.bias, num_params: 1024, non_zero_params: 1024\n",
      "name: triplet_projector_2d.3.weight, num_params: 524288, non_zero_params: 524288\n",
      "name: triplet_projector_2d.3.bias, num_params: 512, non_zero_params: 512\n",
      "name: mlp_3d.0.weight, num_params: 387072, non_zero_params: 387072\n",
      "name: mlp_3d.0.bias, num_params: 504, non_zero_params: 504\n",
      "name: mlp_3d.1.weight, num_params: 504, non_zero_params: 504\n",
      "name: mlp_3d.1.bias, num_params: 504, non_zero_params: 504\n",
      "name: rel_predictor_3d.fc1.weight, num_params: 262144, non_zero_params: 262144\n",
      "name: rel_predictor_3d.fc1.bias, num_params: 512, non_zero_params: 512\n",
      "name: rel_predictor_3d.fc2.weight, num_params: 131072, non_zero_params: 131072\n",
      "name: rel_predictor_3d.fc2.bias, num_params: 256, non_zero_params: 256\n",
      "name: rel_predictor_3d.fc3.weight, num_params: 6656, non_zero_params: 6656\n",
      "name: rel_predictor_3d.fc3.bias, num_params: 26, non_zero_params: 26\n",
      "name: rel_predictor_2d.fc1.weight, num_params: 262144, non_zero_params: 262144\n",
      "name: rel_predictor_2d.fc1.bias, num_params: 512, non_zero_params: 512\n",
      "name: rel_predictor_2d.fc2.weight, num_params: 131072, non_zero_params: 131072\n",
      "name: rel_predictor_2d.fc2.bias, num_params: 256, non_zero_params: 256\n",
      "name: rel_predictor_2d.fc3.weight, num_params: 6656, non_zero_params: 6656\n",
      "name: rel_predictor_2d.fc3.bias, num_params: 26, non_zero_params: 26\n",
      "name: obj_predictor_2d.weight, num_params: 81920, non_zero_params: 81920\n",
      "name: obj_predictor_2d.bias, num_params: 160, non_zero_params: 160\n",
      "name: obj_predictor_3d.weight, num_params: 81920, non_zero_params: 81920\n",
      "name: obj_predictor_3d.bias, num_params: 160, non_zero_params: 160\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        num_params = param.numel()\n",
    "        if name.endswith('weight'):\n",
    "            non_zero_params = torch.count_nonzero(param).item()\n",
    "        else:\n",
    "            non_zero_params = num_params\n",
    "        print(f'name: {name}, num_params: {num_params}, non_zero_params: {non_zero_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        num_params = param.numel()\n",
    "        if name.endswith('weight'):\n",
    "            non_zero_params = torch.count_nonzero(param).item()\n",
    "        else:\n",
    "            non_zero_params = num_params\n",
    "        print(f'name: {name}, num_params: {num_params}, non_zero_params: {non_zero_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', TripletGCN())\n",
      "('aggr_module', SumAggregation())\n",
      "('nn1', Sequential(\n",
      "  (0): Linear(in_features=1280, out_features=512, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=512, out_features=1280, bias=True)\n",
      "  (3): ReLU()\n",
      "))\n",
      "('nn1.0', Linear(in_features=1280, out_features=512, bias=True))\n",
      "('nn1.1', ReLU())\n",
      "('nn1.2', Linear(in_features=512, out_features=1280, bias=True))\n",
      "('nn1.3', ReLU())\n",
      "('nn2', Sequential(\n",
      "  (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "))\n",
      "('nn2.0', Linear(in_features=512, out_features=512, bias=True))\n",
      "('nn2.1', ReLU())\n",
      "('nn2.2', Linear(in_features=512, out_features=512, bias=True))\n"
     ]
    }
   ],
   "source": [
    "tripletModel = model.model.gcn.gconvs[0]\n",
    "layers = []\n",
    "for m in tripletModel.named_modules():\n",
    "    print(m)\n",
    "#     if isinstance(m, torch.nn.Linear):\n",
    "#         layers.append(m)\n",
    "#     elif isinstance(m, torch.nn.modules.conv._ConvNd):\n",
    "#         layers.append(m)\n",
    "# print(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TripletGCNModel(\n",
       "  (gconvs): ModuleList(\n",
       "    (0): TripletGCN()\n",
       "    (1): TripletGCN()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.gcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in model.model.named_modules():\n",
    "    if isinstance(module, torch.nn.Linear):\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.5)\n",
    "        prune.remove(module, 'weight')\n",
    "    elif isinstance(module, torch.nn.Conv1d):\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.5)\n",
    "        prune.remove(module, 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SGFN' object has no attribute 'mmg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmmg\u001b[49m\u001b[38;5;241m.\u001b[39mself_attn\n",
      "File \u001b[0;32m~/miniconda3/envs/vlsat/lib/python3.8/site-packages/torch/nn/modules/module.py:1207\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1206\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1207\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SGFN' object has no attribute 'mmg'"
     ]
    }
   ],
   "source": [
    "model.model.mmg.self_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=512, bias=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.mmg.self_attn[0].attention.fc_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_pruning as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head #0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MMG_student' object has no attribute 'head_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmmg\u001b[38;5;241m.\u001b[39mmodules():\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHead #\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39mhead_id)\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Before Pruning] Num Heads: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, Head Dim: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m =>\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39m(m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead_dim\u001b[49m))\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m      6\u001b[0m     head_id\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/vlsat/lib/python3.8/site-packages/torch/nn/modules/module.py:1207\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1206\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1207\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MMG_student' object has no attribute 'head_dim'"
     ]
    }
   ],
   "source": [
    "def apply_pruning(self, apply_part):\n",
    "        if apply_part == \"encoder\":\n",
    "            encoders = ['obj_encoder', 'rel_encoder_2d', 'rel_encoder_3d']\n",
    "            for encoder_name in encoders:\n",
    "                print(f\"encoder: {encoder_name} pruning:{self.pruning_ratio} start!\")\n",
    "                for name, module in getattr(self.model, encoder_name).named_modules():\n",
    "                    if isinstance(module, torch.nn.Conv1d):\n",
    "                        prune.l1_unstructured(module, name='weight', amount=self.pruning_ratio)\n",
    "                        prune.remove(module, 'weight')\n",
    "        elif apply_part == \"gnn\":\n",
    "            print(\"gnn pruning start\")\n",
    "            gnn_name = 'mmg'\n",
    "            print(f\"gnn: {gnn_name} pruning:{self.pruning_ratio} start!\")\n",
    "            for name, module in getattr(self.model, gnn_name).named_modules():\n",
    "                if isinstance(module, torch.nn.Linear):\n",
    "                    prune.l1_unstructured(module, name='weight', amount=self.pruning_ratio)\n",
    "                    prune.remove(module, 'weight')\n",
    "        elif apply_part == \"classifier\":\n",
    "            print(f\"classifier: {apply_part} pruning:{self.pruning_ratio} start!\")\n",
    "            classifiers = ['obj_predictor_3d', 'rel_predictor_3d', 'obj_predictor_2d', 'rel_predictor_2d']\n",
    "            for predicator in classifiers:\n",
    "                for name, module in getattr(self.model, predicator).named_modules():\n",
    "                    if isinstance(module, torch.nn.Linear):\n",
    "                        prune.l1_unstructured(module, name='weight', amount=self.pruning_ratio)\n",
    "                        prune.remove(module, 'weight')\n",
    "        elif apply_part == 'all':\n",
    "            print(f\"ALL Pruning start!\")\n",
    "            for name, module in self.model.named_modules():\n",
    "                if isinstance(module, torch.nn.Linear):\n",
    "                    prune.l1_unstructured(module, name='weight', amount=self.pruning_ratio)\n",
    "                    prune.remove(module, 'weight')\n",
    "                elif isinstance(module, torch.nn.Conv1d):\n",
    "                    prune.l1_unstructured(module, name='weight', amount=self.pruning_ratio)\n",
    "                    prune.remove(module, 'weight')\n",
    "        else:\n",
    "            print(\"pruning error!\")\n",
    "        print(f\"{apply_part} pruning success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.862275242805481\n",
      "Epoch 2, Loss: 0.6179301738739014\n",
      "Epoch 3, Loss: 0.45785441994667053\n",
      "Epoch 4, Loss: 0.3521365225315094\n",
      "Epoch 5, Loss: 0.28182896971702576\n",
      "conv1 weight after pruning and training:\n",
      "Parameter containing:\n",
      "tensor([[[ 4.7807e-03, -4.5514e-01,  6.1754e-04]],\n",
      "\n",
      "        [[-4.4016e-01, -9.2592e-04, -2.4921e-01]],\n",
      "\n",
      "        [[ 1.5271e-03,  3.5766e-01, -2.8726e-01]],\n",
      "\n",
      "        [[ 1.4692e-01,  4.4684e-03,  3.4911e-01]],\n",
      "\n",
      "        [[ 3.2163e-01,  4.3871e-04,  4.4892e-01]],\n",
      "\n",
      "        [[-4.4697e-03,  2.4309e-01, -5.4016e-01]],\n",
      "\n",
      "        [[-4.4790e-01,  4.4176e-01, -5.0021e-01]],\n",
      "\n",
      "        [[-1.7102e-03,  3.6067e-01, -1.3293e-01]],\n",
      "\n",
      "        [[-2.9553e-03, -3.6057e-03, -5.1928e-01]],\n",
      "\n",
      "        [[ 2.9437e-01, -2.0267e-01, -1.5559e-03]],\n",
      "\n",
      "        [[ 2.3055e-01,  5.6920e-01, -2.5067e-03]],\n",
      "\n",
      "        [[-4.3774e-01,  2.5613e-01, -4.2329e-01]],\n",
      "\n",
      "        [[ 3.3195e-01,  9.8718e-04,  4.0817e-01]],\n",
      "\n",
      "        [[-7.6961e-04, -5.4603e-01,  4.5536e-01]],\n",
      "\n",
      "        [[-3.9488e-01,  4.3384e-01,  3.0693e-01]],\n",
      "\n",
      "        [[-4.3849e-01,  3.1398e-01,  4.9767e-01]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.optim as optim\n",
    "\n",
    "# Seed 설정\n",
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_random_seed(2020)\n",
    "\n",
    "# 간단한 모델 정의\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 3, 1)  # Conv1d 출력 크기에 맞게 Linear 층 수정\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleModel()\n",
    "\n",
    "# Pruning 적용\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Conv1d):\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.3)\n",
    "        prune.remove(module, 'weight')\n",
    "\n",
    "# 학습 설정\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Dummy 데이터\n",
    "inputs = torch.randn(10, 1, 5)\n",
    "targets = torch.randn(10, 1)\n",
    "\n",
    "# 학습\n",
    "for epoch in range(5):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# 가지치기된 파라미터 확인\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Conv1d):\n",
    "        print(f'{name} weight after pruning and training:')\n",
    "        print(module.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlsat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
